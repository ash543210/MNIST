{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import copy\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_data = pd.read_csv(r\"C:\\Users\\shaik\\OneDrive\\Desktop\\MNIST\\MindBigData-EP-v1.0\\EP1.01.txt\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_data.columns = [\"ID\", \"Event ID\", \"Device\", \"Channel\", \"Label\", \"HzCaptured\", \"Signal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops through the data and extracts all of the unique labels.\n",
    "def get_labels_in_set(dataset, labelcolname=\"Label\"):\n",
    "    listoflabels = []\n",
    "    for i in range(len(dataset)):\n",
    "        newlabel = dataset[labelcolname][i]\n",
    "        if newlabel not in listoflabels:\n",
    "            listoflabels.append(newlabel)\n",
    "    return listoflabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels In Data Set:  [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Unique Labels in IN Dataset\n",
    "listoflabels = get_labels_in_set(EP_data, \"Label\")\n",
    "print(\"Labels In Data Set: \", sorted(listoflabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data by Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters out all observations with <250 Hz Captured. Needed for the 250 nodes in the input layer of our neural network.\n",
    "def filter_data(dataset, Hz_colname, filternum=250):\n",
    "    data_filter = dataset[dataset[Hz_colname] >= filternum]\n",
    "    print(\"lengths of dataset\", len(dataset),\n",
    "          \"length of filtered set:\", len(data_filter),\n",
    "          \"length that was filtered out:\", len(dataset[dataset[Hz_colname] < filternum]))\n",
    "    print(\"Percent of Original Data Retained:\", round(len(data_filter) / len(dataset) * 100, 2), \"%\")\n",
    "    return data_filter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths of dataset 910476 length of filtered set: 910056 length that was filtered out: 420\n",
      "Percent of Original Data Retained: 99.95 %\n"
     ]
    }
   ],
   "source": [
    "EP_data_filter = filter_data(EP_data, \"HzCaptured\", 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EP_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data by -1 Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_negatives(dataset, label_colname):\n",
    "    data_filter = dataset[dataset[label_colname] != -1]\n",
    "    print(\"lengths of dataset\", len(dataset),\n",
    "          \"length of filtered set\", len(data_filter),\n",
    "          \"length that was filtered out\", len(dataset[dataset[label_colname] == -1]))\n",
    "    print(\"Percent of Original Data Retained\", round(len(data_filter) / len(dataset) * 100, 2), \"%\")\n",
    "    return data_filter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths of dataset 910056 length of filtered set 907830 length that was filtered out 2226\n",
      "Percent of Original Data Retained 99.76 %\n"
     ]
    }
   ],
   "source": [
    "EP_data_filter = filter_negatives(EP_data_filter, \"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Signal Strings to Arrays of Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(907830, 7)\n"
     ]
    }
   ],
   "source": [
    "EP_data_array = EP_data_filter.to_numpy()\n",
    "print(EP_data_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This converts the string signal data into an array and then converts each string element into a float element.\n",
    "def string_to_float(stringed_signal_data):\n",
    "    float_signal_data = np.empty((len(stringed_signal_data)), dtype=object)\n",
    "    for n in range(len(float_signal_data)):\n",
    "        single_signal_observation = stringed_signal_data[n][6].split(\",\")\n",
    "        single_signal_observation = [float(i) for i in single_signal_observation]        \n",
    "        float_signal_data[n] = single_signal_observation\n",
    "    print(\"The Shape of the Array we created after converting to floats:\", float_signal_data.shape)\n",
    "    print(\"The Shape of the Original Array of Stringed Signal Data:     \", stringed_signal_data[:,6].shape)\n",
    "\n",
    "    return float_signal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the Array we created after converting to floats: (907830,)\n",
      "The Shape of the Original Array of Stringed Signal Data:      (907830,)\n"
     ]
    }
   ],
   "source": [
    "EP_signal_float = string_to_float(EP_data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EP_data_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping the Signal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_signal(signal_float):\n",
    "    signal_cropped = np.empty((len(signal_float)), dtype=object)\n",
    "    for n in range(len(signal_cropped)):\n",
    "        signal_cropped[n] = np.array(signal_float[n][:250])\n",
    "    print(\"Shape of 1st sample in signal\", signal_cropped[0].shape)\n",
    "    print(\"Shape of all signal data\", signal_cropped.shape)\n",
    "    return signal_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 1st sample in signal (250,)\n",
      "Shape of all signal data (907830,)\n"
     ]
    }
   ],
   "source": [
    "EP_signal_cropped = crop_signal(EP_signal_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EP_signal_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping X (by event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This groups everything. First, create an empty array, then create mini arrays of c observations grouped together.\n",
    "def group_x(x_,channels):\n",
    "    grouped_x = np.empty((len(x_)//channels), dtype=object)\n",
    "    temp_x = []\n",
    "    for i in range(len(x_)):\n",
    "        temp_x.append(x_[i])\n",
    "        if (i+1) % channels == 0:\n",
    "            j = ((i+1)//channels)-1\n",
    "            grouped_x[j] = np.array(temp_x)\n",
    "            temp_x = []\n",
    "    \n",
    "    print(\"Check if everything is of type array:\", type(grouped_x), type(grouped_x[10]), type(grouped_x[15][9]))\n",
    "    print(\"Shape of Grouped X:\", grouped_x.shape, \"\\nShape of Original X Divided by C:\", len(x_)//channels)\n",
    "    \n",
    "    return grouped_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if everything is of type array: <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shape of Grouped X: (64845,) \n",
      "Shape of Original X Divided by C: 64845\n"
     ]
    }
   ],
   "source": [
    "EP_grouped_x = group_x(EP_signal_cropped, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EP_signal_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EP_grouped_x.dtype # Tensorflow can't handle Objects \"O\" dtypes. Luckily this is automatically fixed when flattening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Input Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_shape(x_, new_shape_order):\n",
    "    if new_shape_order == \"channel-time\":\n",
    "        copy_x = []\n",
    "        for i in x_:\n",
    "            copy_x.append(i)\n",
    "        copy_x = np.array(copy_x)\n",
    "    elif new_shape_order == \"time-channel\":\n",
    "        copy_x = []\n",
    "        for i in x_:\n",
    "            copy_x.append(i.T)\n",
    "        copy_x = np.array(copy_x)\n",
    "    elif new_shape_order == \"flattened\":\n",
    "        copy_x = []\n",
    "        for i in x_:\n",
    "            copy_x.append(i.T.flatten())\n",
    "        copy_x = np.array(copy_x)\n",
    "    \n",
    "    print(\"New Shape:\", copy_x.shape)\n",
    "    print(\"Sample of X:\", copy_x[13])\n",
    "    return copy_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Shape: (64845, 3500)\n",
      "Sample of X: [4387.692307 4537.435897 4528.205128 ... 4647.692307 3988.717949\n",
      " 4062.051282]\n"
     ]
    }
   ],
   "source": [
    "EP_x = change_shape(EP_grouped_x, \"flattened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EP_grouped_x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64845, 3500)\n"
     ]
    }
   ],
   "source": [
    "print(EP_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  1. 14.]\n",
      " [10. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "temp_x = np.array(([1.0,2.0,3.0],\n",
    "          [4.0,5.0,6.0],\n",
    "          [7.0,1.0,14.0],\n",
    "          [10.0,11.0,12.0]))\n",
    "print(temp_x.shape)\n",
    "print(temp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(x_prescaled):\n",
    "    for feature in range(x_prescaled.T.shape[0]):\n",
    "        feature_min = min(x_prescaled.T[feature])\n",
    "        feature_max = max(x_prescaled.T[feature])\n",
    "        feature_range = feature_max - feature_min\n",
    "        x_prescaled.T[feature] = ( x_prescaled.T[feature] - feature_min ) / feature_range\n",
    "    return x_prescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verified that this works properly\n",
    "scaled_x = scale_features(EP_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64845, 3500)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EP_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalize(x_prenormalized):\n",
    "    for feature in range(x_prenormalized.T.shape[0]):\n",
    "        feature_mean = sum(x_prenormalized.T[feature]) / len(x_prenormalized.T[feature])\n",
    "        x_prenormalized.T[feature] = x_prenormalized.T[feature] - feature_mean\n",
    "    return x_prenormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verified that this works properly.\n",
    "normalized_x = mean_normalize(scaled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "del scaled_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_x(pre_x, channels, timepoints):\n",
    "    new_x = np.reshape(pre_x, (pre_x.shape[0], channels, timepoints))\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_x = reshape_x(normalized_x, 14, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "del normalized_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Hot Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y(dataarray_set, c):\n",
    "    y_preprocess = dataarray_set[:,4]\n",
    "    print(\"Y Original Length:\", len(y_preprocess), \"\\nExamples of Y:\", y_preprocess[:30])\n",
    "    \n",
    "    y_divided = [y_preprocess[i] for i in range(len(y_preprocess)) if (i+1)%c == 0] # Extract 1 label per event instead of c\n",
    "    print(\"\\n Y Length after filtering out event duplicates (dividing by c):\", len(y_divided))\n",
    "    print(\"Examples of Y after filtering:\", y_divided[:30])\n",
    "    \n",
    "    return y_divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates an equivalent array of arrays using the encoding system.\n",
    "def encode_hot_y(dataarray_set, labelslist, c):\n",
    "    \n",
    "    y_empty = np.empty((len(dataarray_set)//c), dtype=object)\n",
    "    \n",
    "    for i in range(len(y_empty)):\n",
    "        y_empty[i] = np.zeros((len(labelslist)-1), int)\n",
    "        \n",
    "    y_ = create_y(dataarray_set, c)\n",
    "    \n",
    "    print(\"\\n What y array looks like before assigning 1s: \\n\", y_empty[:10])\n",
    "    \n",
    "    for i in range(len(y_empty)): # This encodes the 1 for each label\n",
    "        n = y_[i]\n",
    "        y_empty[i][n] = 1\n",
    "        \n",
    "    print(\"What y array looks like after assigning 1s: \\n\", y_empty[:10])\n",
    "    \n",
    "    return y_empty\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Original Length: 907830 \n",
      "Examples of Y: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 9 9]\n",
      "\n",
      " Y Length after filtering out event duplicates (dividing by c): 64845\n",
      "Examples of Y after filtering: [6, 7, 9, 9, 0, 0, 8, 6, 6, 5, 6, 3, 9, 4, 2, 8, 9, 0, 7, 2, 7, 1, 1, 9, 5, 0, 1, 2, 6, 1]\n",
      "\n",
      " What y array looks like before assigning 1s: \n",
      " [array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      "What y array looks like after assigning 1s: \n",
      " [array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "EP_encode_y = encode_hot_y(EP_data_array, listoflabels, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EP_data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dtype(y_):\n",
    "    print(\"Previous Dtype:\", y_.dtype)\n",
    "    if y_.dtype == 'O':\n",
    "        y_ = np.vstack(y_[:]).astype(np.float)\n",
    "        print(\"Fixed. New Dtye:\", y_.dtype)\n",
    "        return y_\n",
    "    else:\n",
    "        return \"Not Object Type:\", y_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Dtype: object\n",
      "Fixed. New Dtye: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-96b05abc1e67>:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_ = np.vstack(y_[:]).astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "EP_y = fix_dtype(EP_encode_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EP_encode_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6909651458263397 GB\n",
      "0.004831328988075256 GB\n"
     ]
    }
   ],
   "source": [
    "print(EP_x.nbytes/(1024**3), \"GB\")\n",
    "print(EP_y.nbytes/(1024**3), \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(x, y, dataName):\n",
    "    with h5py.File(dataName + '_x.h5', 'w') as hf:\n",
    "        hf.create_dataset(dataName + \"_x_dataset\", data=x)\n",
    "        \n",
    "    with h5py.File(dataName + \"_y.h5\", \"w\") as hf:\n",
    "        hf.create_dataset(dataName + \"_y_dataset\", data=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(EP_x, EP_y, \"EP_preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EP_x\n",
    "del EP_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, dataname):\n",
    "    with h5py.File(filename, 'r') as hf:\n",
    "        x = hf[dataname][:]\n",
    "    with h5py.File('EP_preprocessed_y.h5', 'r') as hf:\n",
    "        y = hf['EP_preprocessed_y_dataset'][:]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_x(pre_x, channels, timepoints):\n",
    "    new_x = np.reshape(pre_x, (pre_x.shape[0], channels, timepoints))\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(file, data):\n",
    "    x_,y_ = load_data(file, data)\n",
    "    \n",
    "    x_train, x_test = x_[:int(len(x_)*.80)], x_[-int(len(x_)*.20):]\n",
    "    y_train, y_test = y_[:int(len(y_)*.80)], y_[-int(len(y_)*.20):]\n",
    "    \n",
    "    print(\"X train shape: \", x_train.shape)\n",
    "    print(\"X test shape: \", x_test.shape)\n",
    "    print(\"Y train shape: \", y_train.shape)\n",
    "    print(\"Y test shape: \", y_test.shape)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN(convLayer, denseLayer, nodes):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Conv1D(nodes, 1, input_shape=(x_train.shape[1:]), data_format=\"channels_last\", activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "\n",
    "    for l in range(convLayer-1):\n",
    "        model.add(keras.layers.Conv1D(nodes, 1, activation=\"relu\"))\n",
    "        model.add(keras.layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(keras.layers.Flatten())\n",
    "\n",
    "    for l in range(denseLayer-1):\n",
    "        model.add(keras.layers.Dense(nodes, activation=\"relu\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensorboard(model_name, logdir):\n",
    "    tensorboard = TensorBoard(log_dir=f'{logdir}\\\\{model_name}')\n",
    "    #tensorboard = TensorBoard(log_dir=f'logs\\\\{model_name}')\n",
    "    print(\"Model Name:\", model_name)\n",
    "    return tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [3,2]\n",
    "dense_layers = [2,1]\n",
    "layer_sizes = [256,64,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Files and Data Sets\n",
    "data_files = [\"EP_preprocessed_x.h5\"]\n",
    "\n",
    "data_sets = [\"EP_preprocessed_x_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (51876, 14, 250)\n",
      "X test shape:  (12969, 14, 250)\n",
      "Y train shape:  (51876, 10)\n",
      "Y test shape:  (12969, 10)\n",
      "Model Name: CNN-3-conv-2-dense-256-nodes-1650307316\n",
      "Epoch 1/10\n",
      "   1/1622 [..............................] - ETA: 1s - loss: 2.3011 - accuracy: 0.1250WARNING:tensorflow:From C:\\Users\\shaik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1622/1622 [==============================] - 62s 38ms/step - loss: 2.3035 - accuracy: 0.0991 - val_loss: 2.3025 - val_accuracy: 0.0990\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 47s 29ms/step - loss: 2.3030 - accuracy: 0.1011 - val_loss: 2.3030 - val_accuracy: 0.0989\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 50s 31ms/step - loss: 2.3029 - accuracy: 0.1000 - val_loss: 2.3034 - val_accuracy: 0.1022\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 52s 32ms/step - loss: 2.3030 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.0997\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 51s 31ms/step - loss: 2.3031 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1021\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 29s 18ms/step - loss: 2.3031 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1022\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 16s 10ms/step - loss: 2.3031 - accuracy: 0.0996 - val_loss: 2.3031 - val_accuracy: 0.0998\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 19s 11ms/step - loss: 2.3029 - accuracy: 0.1005 - val_loss: 2.3029 - val_accuracy: 0.1022\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 18s 11ms/step - loss: 2.3030 - accuracy: 0.1013 - val_loss: 2.3030 - val_accuracy: 0.1022\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 19s 12ms/step - loss: 2.3029 - accuracy: 0.1010 - val_loss: 2.3026 - val_accuracy: 0.1029\n",
      "Model Name: CNN-3-conv-2-dense-64-nodes-1650307685\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 8:06 - loss: 2.3097 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0113s vs `on_train_batch_end` time: 0.5888s). Check your callbacks.\n",
      "1622/1622 [==============================] - 8s 5ms/step - loss: 2.3031 - accuracy: 0.1016 - val_loss: 2.3025 - val_accuracy: 0.1026\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 6s 4ms/step - loss: 2.3029 - accuracy: 0.1025 - val_loss: 2.3028 - val_accuracy: 0.0975\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 6s 4ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3023 - val_accuracy: 0.1021\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 6s 4ms/step - loss: 2.3028 - accuracy: 0.1011 - val_loss: 2.3026 - val_accuracy: 0.1022\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 6s 4ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3026 - val_accuracy: 0.1037\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 6s 4ms/step - loss: 2.3028 - accuracy: 0.1009 - val_loss: 2.3025 - val_accuracy: 0.1022\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3026 - accuracy: 0.1027 - val_loss: 2.3028 - val_accuracy: 0.1025\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3027 - accuracy: 0.1017 - val_loss: 2.3027 - val_accuracy: 0.1033\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3027 - val_accuracy: 0.1033\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 6s 4ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1030\n",
      "Model Name: CNN-3-conv-2-dense-16-nodes-1650307748\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 8:47 - loss: 2.3018 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0092s vs `on_train_batch_end` time: 0.6428s). Check your callbacks.\n",
      "1622/1622 [==============================] - 4s 2ms/step - loss: 2.3029 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0999\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.0999\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0982\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 4s 2ms/step - loss: 2.3026 - accuracy: 0.1003 - val_loss: 2.3029 - val_accuracy: 0.0991\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 4s 2ms/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3028 - val_accuracy: 0.0988\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3025 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.0995\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3025 - val_accuracy: 0.1009\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1026 - val_loss: 2.3026 - val_accuracy: 0.1026\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.1022 - val_loss: 2.3027 - val_accuracy: 0.0999\n",
      "Model Name: CNN-3-conv-1-dense-256-nodes-1650307782\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 6:45 - loss: 2.3055 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0122s vs `on_train_batch_end` time: 0.4882s). Check your callbacks.\n",
      "1622/1622 [==============================] - 12s 8ms/step - loss: 2.3036 - accuracy: 0.1003 - val_loss: 2.3029 - val_accuracy: 0.0997\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 11s 7ms/step - loss: 2.3033 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 11s 7ms/step - loss: 2.3031 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1019\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 11s 7ms/step - loss: 2.3029 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1004\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 11s 7ms/step - loss: 2.3030 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1026\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 11s 7ms/step - loss: 2.3030 - accuracy: 0.1018 - val_loss: 2.3042 - val_accuracy: 0.0995\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 11s 7ms/step - loss: 2.3032 - accuracy: 0.0990 - val_loss: 2.3029 - val_accuracy: 0.0995\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1025\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 12s 7ms/step - loss: 2.3028 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.1021\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 12s 7ms/step - loss: 2.3028 - accuracy: 0.1014 - val_loss: 2.3028 - val_accuracy: 0.0985\n",
      "Model Name: CNN-3-conv-1-dense-64-nodes-1650307899\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 8:02 - loss: 2.3044 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.5956s). Check your callbacks.\n",
      "1622/1622 [==============================] - 6s 4ms/step - loss: 2.3033 - accuracy: 0.0999 - val_loss: 2.3025 - val_accuracy: 0.1049\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3030 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1017\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3028 - accuracy: 0.1031 - val_loss: 2.3027 - val_accuracy: 0.1043\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3026 - accuracy: 0.1018 - val_loss: 2.3030 - val_accuracy: 0.1020\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1002\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3025 - accuracy: 0.1006 - val_loss: 2.3029 - val_accuracy: 0.1022\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3025 - accuracy: 0.1001 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3024 - accuracy: 0.1004 - val_loss: 2.3031 - val_accuracy: 0.0985\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3022 - accuracy: 0.1028 - val_loss: 2.3037 - val_accuracy: 0.1029\n",
      "Model Name: CNN-3-conv-1-dense-16-nodes-1650307952\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 9:34 - loss: 2.3041 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.7045s). Check your callbacks.\n",
      "1622/1622 [==============================] - 4s 3ms/step - loss: 2.3029 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.1015\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1032\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.0974\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3028 - accuracy: 0.1007 - val_loss: 2.3025 - val_accuracy: 0.1029\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3025 - val_accuracy: 0.1023\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3028 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.0988\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3029 - val_accuracy: 0.0992\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.1029\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1014 - val_loss: 2.3027 - val_accuracy: 0.1046\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.1032\n",
      "Model Name: CNN-2-conv-2-dense-256-nodes-1650307985\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 5:54 - loss: 2.3014 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.4280s). Check your callbacks.\n",
      "1622/1622 [==============================] - 14s 8ms/step - loss: 2.3039 - accuracy: 0.1008 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 14s 9ms/step - loss: 2.3032 - accuracy: 0.1020 - val_loss: 2.3028 - val_accuracy: 0.0994\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 14s 8ms/step - loss: 2.3032 - accuracy: 0.0969 - val_loss: 2.3025 - val_accuracy: 0.1045\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 14s 9ms/step - loss: 2.3030 - accuracy: 0.1007 - val_loss: 2.3034 - val_accuracy: 0.1024\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 13s 8ms/step - loss: 2.3031 - accuracy: 0.1018 - val_loss: 2.3028 - val_accuracy: 0.0970\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 13s 8ms/step - loss: 2.3029 - accuracy: 0.1015 - val_loss: 2.3027 - val_accuracy: 0.1011\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 13s 8ms/step - loss: 2.3028 - accuracy: 0.1039 - val_loss: 2.3018 - val_accuracy: 0.1053\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 13s 8ms/step - loss: 2.3020 - accuracy: 0.1063 - val_loss: 2.3006 - val_accuracy: 0.1126\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 13s 8ms/step - loss: 2.3008 - accuracy: 0.1096 - val_loss: 2.2991 - val_accuracy: 0.1171\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 13s 8ms/step - loss: 2.2995 - accuracy: 0.1150 - val_loss: 2.2987 - val_accuracy: 0.1159\n",
      "Model Name: CNN-2-conv-2-dense-64-nodes-1650308121\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 8:12 - loss: 2.3009 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_train_batch_end` time: 0.6028s). Check your callbacks.\n",
      "1622/1622 [==============================] - 6s 4ms/step - loss: 2.3032 - accuracy: 0.1020 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3029 - accuracy: 0.1020 - val_loss: 2.3030 - val_accuracy: 0.0995\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3027 - val_accuracy: 0.1010\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3019 - accuracy: 0.1058 - val_loss: 2.3018 - val_accuracy: 0.1072\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3007 - accuracy: 0.1116 - val_loss: 2.2996 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.2992 - accuracy: 0.1134 - val_loss: 2.2976 - val_accuracy: 0.1149\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.2984 - accuracy: 0.1142 - val_loss: 2.2961 - val_accuracy: 0.1212\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.2966 - accuracy: 0.1181 - val_loss: 2.2951 - val_accuracy: 0.1174\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.2955 - accuracy: 0.1167 - val_loss: 2.2944 - val_accuracy: 0.1220\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.2943 - accuracy: 0.1222 - val_loss: 2.2933 - val_accuracy: 0.1249\n",
      "Model Name: CNN-2-conv-2-dense-16-nodes-1650308174\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 6:57 - loss: 2.3023 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.5141s). Check your callbacks.\n",
      "1622/1622 [==============================] - 4s 2ms/step - loss: 2.3029 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3025 - val_accuracy: 0.1025\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1025\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1030\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3025 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.1003\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3025 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.0990\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.1020 - val_loss: 2.3026 - val_accuracy: 0.1010\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3021 - accuracy: 0.1027 - val_loss: 2.3025 - val_accuracy: 0.1015\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3017 - accuracy: 0.1052 - val_loss: 2.3023 - val_accuracy: 0.1069\n",
      "Model Name: CNN-2-conv-1-dense-256-nodes-1650308207\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 5:24 - loss: 2.3004 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.3909s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622/1622 [==============================] - 11s 7ms/step - loss: 2.3042 - accuracy: 0.0989 - val_loss: 2.3029 - val_accuracy: 0.1026\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 10s 6ms/step - loss: 2.3032 - accuracy: 0.1034 - val_loss: 2.3027 - val_accuracy: 0.1032\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 10s 6ms/step - loss: 2.3025 - accuracy: 0.1048 - val_loss: 2.3018 - val_accuracy: 0.1026\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 10s 6ms/step - loss: 2.3014 - accuracy: 0.1096 - val_loss: 2.3004 - val_accuracy: 0.1077\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 10s 6ms/step - loss: 2.2999 - accuracy: 0.1133 - val_loss: 2.2992 - val_accuracy: 0.1095\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 10s 6ms/step - loss: 2.2985 - accuracy: 0.1163 - val_loss: 2.2974 - val_accuracy: 0.1149\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 10s 6ms/step - loss: 2.2973 - accuracy: 0.1174 - val_loss: 2.2966 - val_accuracy: 0.1139\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 10s 6ms/step - loss: 2.2966 - accuracy: 0.1170 - val_loss: 2.2960 - val_accuracy: 0.1205\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 10s 6ms/step - loss: 2.2956 - accuracy: 0.1203 - val_loss: 2.2957 - val_accuracy: 0.1165\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 10s 6ms/step - loss: 2.2951 - accuracy: 0.1211 - val_loss: 2.2954 - val_accuracy: 0.1184\n",
      "Model Name: CNN-2-conv-1-dense-64-nodes-1650308309\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 6:34 - loss: 2.3069 - accuracy: 0.0469  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_train_batch_end` time: 0.4822s). Check your callbacks.\n",
      "1622/1622 [==============================] - 6s 3ms/step - loss: 2.3033 - accuracy: 0.1013 - val_loss: 2.3030 - val_accuracy: 0.0988\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3028 - val_accuracy: 0.1067\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3028 - accuracy: 0.1008 - val_loss: 2.3023 - val_accuracy: 0.1013\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3022 - accuracy: 0.1046 - val_loss: 2.3017 - val_accuracy: 0.1066\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3012 - accuracy: 0.1087 - val_loss: 2.3008 - val_accuracy: 0.1141\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3008 - accuracy: 0.1103 - val_loss: 2.2998 - val_accuracy: 0.1109\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.2996 - accuracy: 0.1115 - val_loss: 2.3001 - val_accuracy: 0.1126\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.2986 - accuracy: 0.1140 - val_loss: 2.2994 - val_accuracy: 0.1154\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.2978 - accuracy: 0.1164 - val_loss: 2.2983 - val_accuracy: 0.1190\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.2972 - accuracy: 0.1168 - val_loss: 2.2972 - val_accuracy: 0.1159\n",
      "Model Name: CNN-2-conv-1-dense-16-nodes-1650308360\n",
      "Epoch 1/10\n",
      "   2/1622 [..............................] - ETA: 5:52 - loss: 2.2993 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.4297s). Check your callbacks.\n",
      "1622/1622 [==============================] - 5s 3ms/step - loss: 2.3029 - accuracy: 0.1018 - val_loss: 2.3025 - val_accuracy: 0.1032\n",
      "Epoch 2/10\n",
      "1622/1622 [==============================] - 4s 2ms/step - loss: 2.3026 - accuracy: 0.1010 - val_loss: 2.3027 - val_accuracy: 0.1043\n",
      "Epoch 3/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3028 - val_accuracy: 0.0989\n",
      "Epoch 4/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.1021 - val_loss: 2.3028 - val_accuracy: 0.1024\n",
      "Epoch 5/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3025 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.1002\n",
      "Epoch 6/10\n",
      "1622/1622 [==============================] - 4s 2ms/step - loss: 2.3023 - accuracy: 0.1012 - val_loss: 2.3030 - val_accuracy: 0.1006\n",
      "Epoch 7/10\n",
      "1622/1622 [==============================] - 4s 2ms/step - loss: 2.3021 - accuracy: 0.1035 - val_loss: 2.3030 - val_accuracy: 0.1045\n",
      "Epoch 8/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3018 - accuracy: 0.1026 - val_loss: 2.3028 - val_accuracy: 0.1035\n",
      "Epoch 9/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3015 - accuracy: 0.1062 - val_loss: 2.3029 - val_accuracy: 0.1042\n",
      "Epoch 10/10\n",
      "1622/1622 [==============================] - 3s 2ms/step - loss: 2.3014 - accuracy: 0.1037 - val_loss: 2.3023 - val_accuracy: 0.1046\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_files)):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_files[i], data_sets[i])\n",
    "    \n",
    "    for conv_layer in conv_layers:\n",
    "        for dense_layer in dense_layers:\n",
    "            for layer_size in layer_sizes:\n",
    "\n",
    "                # --- Tensorboard Callback ---\n",
    "                NAME = f\"CNN-{conv_layer}-conv-{dense_layer}-dense-{layer_size}-nodes-{int(time.time())}\"\n",
    "                tensorboard = get_tensorboard(model_name=NAME, logdir='logs_ConvNet')\n",
    "\n",
    "                # --- Convolutional Neural Network ---\n",
    "                model = build_CNN(conv_layer, dense_layer, layer_size)\n",
    "                model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])    \n",
    "                model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
